%%=============================================================================
%% Samenvatting
%%=============================================================================

\chapter*{Samenvatting}

Sinds de opkomst van krachtige AI- en deep learning-modellen is data uitgegroeid tot een essentiële en vaak beperkende factor in het ontwikkelingsproces. Waar eenvoudige modellen vaak kunnen volstaan met beperkte en eenvoudige datasets, vereisen complexere modellen -- zoals die voor objectdetectie -- steeds grotere en rijkere hoeveelheden gelabelde data. Dit vormt een belangrijk probleem in domeinen zoals sonarbeeldvorming, waar dergelijke datasets niet beschikbaar zijn als kant-en-klare bronnen en handmatige annotatie buitengewoon tijdsintensief en kostbaar is. Dit onderzoek richt zich daarom op de centrale vraag: hoe kunnen semi-supervised en self-supervised leermethoden het labelproces bij objectdetectie in sonardata versnellen, zonder significant verlies aan nauwkeurigheid? \\

Om deze vraag te beantwoorden is een experimenteel kader opgezet waarin drie benaderingen zijn onderzocht: een volledig supervised baseline gebaseerd op Faster R-CNN, een semi-supervised model met FixMatch, en een self-supervised strategie waarbij een BYOL-model wordt gepretraind en vervolgens gebruikt als backbone binnen een Faster R-CNN-architectuur. De experimenten zijn uitgevoerd op een publieke sonardataset bestaande uit 7600 gelabelde sonarbeelden. Voor de supervised baseline is het model getraind op verschillende hoeveelheden gelabelde data: 1\%, 5\%, 10\%, 50\% en 100\%. De bijbehorende mAP-scores tonen een sterke daling in nauwkeurigheid naarmate de hoeveelheid gelabelde data afneemt, met resultaten variërend van 0.7717 (100\%) tot slechts 0.2799 bij gebruik van 1\% van de data. \\

In het semi-supervised scenario is FixMatch toegepast met 5\% en 10\% gelabelde data, terwijl de resterende data werd gebruikt als ongelabelde input. Deze aanpak resulteerde in mAP-scores van respectievelijk 0.6649 en 0.6828, wat duidelijk betere prestaties zijn dan het supervised model op dezelfde labelniveaus. Voor het self-supervised model werd BYOL gepretraind op de volledige dataset zonder labels. De representaties die dit opleverde zijn vervolgens geïntegreerd in Faster R-CNN, waarbij opnieuw 5\% en 10\% van de data gelabeld werd gebruikt voor training. Deze benadering leverde de hoogste nauwkeurigheid binnen de lage-labelscenario's, met mAP-scores van respectievelijk 0.6452 en 0.7230.

\clearpage

De resultaten van dit onderzoek tonen aan dat zowel semi-supervised als self-supervised technieken effectief zijn in het verminderen van de afhankelijkheid van handmatig gelabelde data, terwijl de modelprestaties grotendeels behouden blijven. Met name self-supervised pretraining via BYOL blijkt zeer waardevol in situaties met beperkte gelabelde data. Deze bevindingen bieden praktische aanknopingspunten voor het ontwikkelen van efficiëntere workflows in sonarbeeldanalyse, en zijn relevant voor bredere toepassingen in domeinen waar gelabelde data schaars of moeilijk te verkrijgen is. Hoewel de resultaten veelbelovend zijn, is vervolgonderzoek nodig om de generaliseerbaarheid naar andere types sonardata of real-time toepassingen te evalueren.