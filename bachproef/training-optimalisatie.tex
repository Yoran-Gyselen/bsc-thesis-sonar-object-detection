\chapter{Training van de verschillende modellen}
\label{ch:training-optimalisatie}

Om betrouwbare en nauwkeurige objectdetectiemodellen te kunnen trainen, vormt een grondige voorbereiding van de data een essentiële eerste stap. Het voorgaande hoofdstuk behandelde dit proces. De dataset is nu in een vorm die gebruikt kan worden om de modellen mee te trainen. Vervolgens werd de implementatie van de gekozen detectiemodellen toegelicht, waarbij de praktische werking en vertaling naar duidelijke en heldere code werd besproken. Met een goed gestructureerde dataset én een robuuste modelimplementatie, is de basis gelegd voor het trainingsproces. In dit hoofdstuk wordt uiteengezet hoe deze modellen vervolgens worden getraind, welke middelen hiervoor nodig zijn, en hoe het model leert om objecten accuraat te detecteren. Deze stap vormt het brugpunt tussen de voorbereiding en de uiteindelijke evaluatie van de modelprestaties. \\

\section{Verschillende resources}

Het trainen van deze objectdetectiemodellen is een intensief proces dat zowel op het vlak van data als computationele resources aanzienlijke vereisten stelt. Zoals uitgelegd in \ref{subsec:definitie-en-gebruik-op-sonarafbeeldingen} combineert objectdetectie classificatie en lokalisatie: het model moet niet alleen herkennen wat er in een afbeelding aanwezig is, maar ook waar het zich bevindt via het voorspellen van \glspl{bounding_box}. Tijdens het trainingsproces worden geannoteerde datasets gebruikt waarbij objecten met klasse-labels en coördinaten zijn aangeduid, zoals in \gls{coco} of Pascal \gls{voc}. Het model leert via een samengestelde \gls{loss_functie}, die typisch zowel classificatiefouten als fouten in de \glspl{bounding_box} omvat. Door middel van \gls{backpropagation} worden de gewichten van het neurale netwerk aangepast om deze gecombineerde \gls{loss_functie} te minimaliseren. Omdat objectdetectie vaak gebaseerd is op diepe \glspl{cnn}, vereist het trainingsproces krachtige hardware. \\

\subsection{CPU}

Omwille van deze vereisten, worden neurale netwerken vrijwel nooit getraind op \glspl{cpu}. Een \gls{cpu} is namelijk zeer goed in het uitvoeren van \emph{general-purpose} taken (besturingssysteem draaien, tekstverwerking, spreadsheets \dots) op een sequentiële manier. Om hiervoor geoptimaliseerd te zijn, bevat een \gls{cpu} relatief weinig cores. Dit varieert meestal tussen de 2 en de 64. Echter draaien deze cores op een hoge tot zeer hoge snelheid, meestal tussen de 2 en de 5 GHz. Het grote nadeel van \glspl{cpu} is dat ze niet geschikt zijn voor taken die sterk geparallelliseerd worden uitgevoerd, zoals het trainen van een neuraal netwerk. Deze taak vergt namelijk een grote hoeveelheid aan matrix- en tensoroperaties, hetgeen efficiënt kan geparallelliseerd worden. \\

\subsection{GPU}

Voor deze use-case wordt dus meestal gebruik gemaakt van één of meerdere \glspl{gpu}. Deze zijn oorspronkelijk bedoeld om beelden te renderen om ze op een monitor weer te geven. Aangezien dit ook een taak is die in hoge mate geparallelliseerd kan worden, is een \gls{gpu} ontworpen met (tien)duizenden kleinere cores in plaats van enkele grote cores. Deze cores hebben dan wel weer een lagere snelheid dan de \gls{cpu}-cores. Doorheen de jaren worden \glspl{gpu} steeds meer gebruikt om parallelliseerbare taken uit te voeren. Naast de training van neurale netwerken gaat dit bijvoorbeeld ook om gaming, 3D-rendering en het minen van cryptomunten zoals Bitcoin. \autocite{Anish_Dev_2014} \\

\subsection{TPU}
\label{subsec:tpu}

Echter is een \gls{gpu} niet speciaal geoptimaliseerd om neurale netwerken te trainen. Dit probleem wordt opgelost door de \gls{tpu}. Dit is een \gls{asic} die speciaal ontworpen is door Google voor het trainen van neurale netwerken. De \gls{tpu} is geoptimaliseerd om matrixvermenigvuldigingen en andere tensoroperaties uit te voeren. \autocite{Jouppi_2017} Het nadeel van de \gls{tpu} is dat de compatibiliteit met third-party frameworks zoals PyTorch beperkt is. \glspl{tpu} werken het beste met TensorFlow, het deep learning-framework van Google zelf. \autocite{Wang_2019} \\

Afhankelijk van modelcomplexiteit, datasetgrootte, batchgrootte en de gebruikte optimalisatie-instellingen kan trainingsduur variëren van enkele uren tot meerdere dagen. Daarom wordt in veel gevallen -- en ook in dit onderzoek -- gebruik gemaakt van vooraf getrainde modellen (pretrained backbones) als uitgangspunt, wat de trainingstijd aanzienlijk kan verkorten en -- vooral bij kleinere datasets -- betere prestaties oplevert. \\

\section{Toegang tot resources}

Er zijn enkele mogelijkheden om toegang te krijgen tot \glspl{gpu} voor het trainen van deep learning-modellen. Zo is het mogelijk om via \href{https://colab.research.google.com/}{Google Colab} gratis toegang te krijgen tot een NVIDIA Tesla T4 \gls{gpu} met 16 GB aan videogeheugen en 2560 CUDA-cores. \autocite{TechPowerUp_Tesla-T4} Ondanks dat deze \gls{gpu} voor het eerst op de markt is gebracht in 2018, is ze nog steeds bruikbaar en nuttig voor AI-workloads. Ook biedt Google via Colab een TPUv2 aan met 8 cores. Een nadeel is wel dat deze resources slechts beperkt toegankelijk zijn afhankelijk van de drukte en hoe zwaar de resource wordt belast. Hierdoor is Google Colab minder geschikt om grote, complexe modellen te trainen. Een ander nadeel is de toegang tot de benodigde data. \\

Op Google Colab is er telkens een virtuele schijf voorzien van zo'n 40-60 GB. Echter wordt deze volledig verwijderd op het moment dat de runtime afgesloten wordt. De data wordt met andere woorden niet persistent opgeslagen. Datasets telkens opnieuw downloaden en voorbereiden verspilt onnodig tijd en resources. Ook is het mogelijk om Colab te koppelen aan Google Drive, maar ook daar is de opslagruimte beperkt (15 GB gratis) en de leessnelheid is te traag om er trainingsdata op te slaan. Deze problemen worden grotendeels verholpen wanneer er gekozen wordt om een dedicated \gls{gpu}-server te huren in de cloud, maar dit doet de kosten natuurlijk oplopen, zeker wanneer er een groot en complex model getraind moet worden. \\

In dit onderzoek werd er daarom gekozen om de modellen te trainen op een dedicated trainingsserver van \href{https://www.exail.com/}{Exail Robotics Belgium}. Deze server is uitgerust met een Intel Core i7-11700K processor met 8 cores, 64 GB DDR4 RAM en een NVIDIA RTX A5000 \gls{gpu} met 24 GB aan videogeheugen en 8192 CUDA-cores. \autocite{TechPowerUp_RTX-A5000}

\section{Supervised training}

De eerste stap in het trainingsproces is het trainen van de gesuperviseerde modellen. 

\section{Semi-supervised training}

\section{Self-supervised training}