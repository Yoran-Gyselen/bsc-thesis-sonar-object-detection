\section{Baseline: supervised Faster R-CNN}

Allereerst is er een baseline-model nodig om de performance van de andere modellen mee te kunnen vergelijken. Dit model zal op de klassieke manier -- namelijk gesuperviseerd -- getraind worden. Dit houdt in dat het model tijdens het trainingsproces voor elke input een output heeft. Het model kan dus voor elke sample het verband leren tussen de features en de labels. De gesuperviseerde baseline zal daarnaast ook gebruikt worden als backbone voor de andere modellen (cf. infra). \\

In dit onderzoek werden al verschillende populaire supervised objectdetectiemodellen besproken. Hoewel deze allemaal geschikt zijn om als baseline te dienen, zal maar één van deze modellen geïmplementeerd worden. Dit om de simpele reden dat dit slechts een proof of concept is en dat de scope anders te ver zou worden uitgebreid. Het model dat geïmplementeerd zal worden is Faster \gls{rcnn}. De argumenten hiervoor zijn terug te vinden in %TODO ref
de literatuurstudie. \\

Er zullen uiteindelijk twee varianten van hetzelfde model gebruikt worden in dit onderzoek. De eerste variant is een Faster \gls{rcnn} model dat getraind is op de volledige trainingsset (7600 samples). Deze variant zal gebruikt worden als baseline om de performantie van de andere modellen (\gls{ssl} en \gls{self-sl}) mee te vergelijken. De tweede variant is qua architectuur volledig gelijk aan de eerste. Het verschil is dat deze getraind zal worden op een (relatief kleine) subset van de trainingsset. Dit model zal gebruikt worden als backbone voor de \gls{ssl}- en \gls{self-sl}-modellen. Dit onderzoek zal voor het gesuperviseerde model het experiment in het onderzoek van \textcite{Xie_2022} zo goed mogelijk proberen nabootsen. Aangezien dezelfde dataset gebruikt wordt in dit onderzoek, zullen de resultaten grotendeels hetzelfde zijn. \\

Specifiek zal een Faster \gls{rcnn}-model met een gepretrainde ResNet-18 backbone gebruikt worden. Dit model wordt in het onderzoek van \textcite{Xie_2022} ook gebruikt en heeft een goede performance op de dataset. Zowel het model als de op ImageNet gepretrainde backbone zijn beschikbaar in de TorchVision bibliotheek. Om ze te gebruiken moeten ze enkel geïmporteerd worden, wat onnodig werk en tijd uitspaart ten opzichte van ze zelf te implementeren en volledig opnieuw te trainen. Er wordt gebruikgemaakt van een Adam-optimizer met een \gls{learning_rate} van $5 \times 10^{-4}}$. Daarnaast wordt een extra optimalisatie toegepast die ook in de paper voorkomt. Op epoch 8 en epoch 11 wordt de \gls{learning_rate} verminderd met 0.1. In totaal zal er 12 epochs gefinetuned worden. Hierbij wordt geen gebruik gemaakt van de \texttt{EarlyStopping}-callback om de resultaten van de paper zo goed mogelijk na te bootsen.