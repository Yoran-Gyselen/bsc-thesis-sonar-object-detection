2025-05-21 14:02:21,956 - Dataset fraction: 0.1
2025-05-21 14:02:21,957 - Seed: 42
2025-05-21 14:02:21,957 - Batch size: 16
2025-05-21 14:02:21,957 - Epochs: 100
2025-05-21 14:02:22,276 - Initially frozen backbone layers: ['layer1.0.conv1.weight', 'layer1.0.conv2.weight', 'layer1.1.conv1.weight', 'layer1.1.conv2.weight', 'layer2.0.conv1.weight', 'layer2.0.conv2.weight', 'layer2.0.downsample.0.weight', 'layer2.1.conv1.weight', 'layer2.1.conv2.weight']
2025-05-21 14:02:57,851 - Epoch 1/100 | Train Loss: 0.7415, LR: 0.000204, mAP@0.5: (skipped — frozen)
2025-05-21 14:03:33,504 - Epoch 2/100 | Train Loss: 0.2782, LR: 0.000402, mAP@0.5: (skipped — frozen)
2025-05-21 14:04:09,681 - Epoch 3/100 | Train Loss: 0.2296, LR: 0.000599, mAP@0.5: (skipped — frozen)
2025-05-21 14:04:09,682 - Unfroze backbone layers at epoch 3: ['layer1.0.conv1.weight', 'layer1.0.conv2.weight', 'layer1.1.conv1.weight', 'layer1.1.conv2.weight', 'layer2.0.conv1.weight', 'layer2.0.conv2.weight', 'layer2.0.downsample.0.weight', 'layer2.1.conv1.weight', 'layer2.1.conv2.weight']
2025-05-21 14:05:09,910 - Epoch 4/100 | Train Loss: 0.2285, LR: 0.000798, mAP@0.5: 0.0171
2025-05-21 14:06:10,877 - Epoch 5/100 | Train Loss: 0.2658, LR: 0.000996, mAP@0.5: 0.0504
2025-05-21 14:07:11,737 - Epoch 6/100 | Train Loss: 0.3148, LR: 0.000996, mAP@0.5: 0.0166
2025-05-21 14:08:13,255 - Epoch 7/100 | Train Loss: 0.2795, LR: 0.000996, mAP@0.5: 0.0426
2025-05-21 14:09:15,399 - Epoch 8/100 | Train Loss: 0.3349, LR: 0.000996, mAP@0.5: 0.1133
2025-05-21 14:10:17,265 - Epoch 9/100 | Train Loss: 0.3436, LR: 0.000996, mAP@0.5: 0.1151
2025-05-21 14:11:19,740 - Epoch 10/100 | Train Loss: 0.3310, LR: 0.000996, mAP@0.5: 0.1532
2025-05-21 14:12:22,122 - Epoch 11/100 | Train Loss: 0.3226, LR: 0.000996, mAP@0.5: 0.2016
2025-05-21 14:13:24,529 - Epoch 12/100 | Train Loss: 0.3146, LR: 0.000996, mAP@0.5: 0.2287
2025-05-21 14:14:27,152 - Epoch 13/100 | Train Loss: 0.3069, LR: 0.000996, mAP@0.5: 0.2427
2025-05-21 14:15:29,718 - Epoch 14/100 | Train Loss: 0.3009, LR: 0.000996, mAP@0.5: 0.2841
2025-05-21 14:16:32,493 - Epoch 15/100 | Train Loss: 0.2982, LR: 0.000996, mAP@0.5: 0.2908
2025-05-21 14:17:35,215 - Epoch 16/100 | Train Loss: 0.2874, LR: 0.000996, mAP@0.5: 0.3402
2025-05-21 14:18:37,854 - Epoch 17/100 | Train Loss: 0.2983, LR: 0.000996, mAP@0.5: 0.3750
2025-05-21 14:19:40,713 - Epoch 18/100 | Train Loss: 0.2905, LR: 0.000996, mAP@0.5: 0.3201
2025-05-21 14:20:43,624 - Epoch 19/100 | Train Loss: 0.2811, LR: 0.000996, mAP@0.5: 0.3430
2025-05-21 14:21:46,360 - Epoch 20/100 | Train Loss: 0.2780, LR: 0.000996, mAP@0.5: 0.4235
2025-05-21 14:22:49,136 - Epoch 21/100 | Train Loss: 0.2756, LR: 0.000996, mAP@0.5: 0.4081
2025-05-21 14:23:51,674 - Epoch 22/100 | Train Loss: 0.2723, LR: 0.000996, mAP@0.5: 0.4865
2025-05-21 14:24:54,450 - Epoch 23/100 | Train Loss: 0.2626, LR: 0.000996, mAP@0.5: 0.4645
2025-05-21 14:25:57,181 - Epoch 24/100 | Train Loss: 0.2685, LR: 0.000996, mAP@0.5: 0.4180
2025-05-21 14:26:59,837 - Epoch 25/100 | Train Loss: 0.2613, LR: 0.000996, mAP@0.5: 0.5172
2025-05-21 14:28:02,660 - Epoch 26/100 | Train Loss: 0.2599, LR: 0.000996, mAP@0.5: 0.4539
2025-05-21 14:29:05,304 - Epoch 27/100 | Train Loss: 0.2571, LR: 0.000996, mAP@0.5: 0.5157
2025-05-21 14:30:07,884 - Epoch 28/100 | Train Loss: 0.2496, LR: 0.000996, mAP@0.5: 0.5363
2025-05-21 14:31:10,478 - Epoch 29/100 | Train Loss: 0.2473, LR: 0.000996, mAP@0.5: 0.5726
2025-05-21 14:32:13,217 - Epoch 30/100 | Train Loss: 0.2467, LR: 0.000996, mAP@0.5: 0.5730
2025-05-21 14:33:15,706 - Epoch 31/100 | Train Loss: 0.2436, LR: 0.000996, mAP@0.5: 0.5691
2025-05-21 14:34:18,350 - Epoch 32/100 | Train Loss: 0.2423, LR: 0.000996, mAP@0.5: 0.5480
2025-05-21 14:35:20,822 - Epoch 33/100 | Train Loss: 0.2416, LR: 0.000996, mAP@0.5: 0.5719
2025-05-21 14:36:23,455 - Epoch 34/100 | Train Loss: 0.2399, LR: 0.000996, mAP@0.5: 0.5737
2025-05-21 14:37:25,987 - Epoch 35/100 | Train Loss: 0.2309, LR: 0.000996, mAP@0.5: 0.6292
2025-05-21 14:38:28,584 - Epoch 36/100 | Train Loss: 0.2278, LR: 0.000996, mAP@0.5: 0.6234
2025-05-21 14:39:31,199 - Epoch 37/100 | Train Loss: 0.2269, LR: 0.000996, mAP@0.5: 0.5114
2025-05-21 14:40:33,851 - Epoch 38/100 | Train Loss: 0.2230, LR: 0.000996, mAP@0.5: 0.5792
2025-05-21 14:41:36,421 - Epoch 39/100 | Train Loss: 0.2260, LR: 0.000996, mAP@0.5: 0.5483
2025-05-21 14:42:38,984 - Epoch 40/100 | Train Loss: 0.2277, LR: 0.000996, mAP@0.5: 0.5839
2025-05-21 14:43:41,476 - Epoch 41/100 | Train Loss: 0.2188, LR: 0.000996, mAP@0.5: 0.6185
2025-05-21 14:44:43,980 - Epoch 42/100 | Train Loss: 0.2179, LR: 0.000996, mAP@0.5: 0.6712
2025-05-21 14:45:46,570 - Epoch 43/100 | Train Loss: 0.2166, LR: 0.000996, mAP@0.5: 0.6182
2025-05-21 14:46:49,163 - Epoch 44/100 | Train Loss: 0.2133, LR: 0.000996, mAP@0.5: 0.6748
2025-05-21 14:47:51,759 - Epoch 45/100 | Train Loss: 0.2123, LR: 0.000996, mAP@0.5: 0.6260
2025-05-21 14:48:54,247 - Epoch 46/100 | Train Loss: 0.2104, LR: 0.000996, mAP@0.5: 0.6412
2025-05-21 14:49:56,691 - Epoch 47/100 | Train Loss: 0.2107, LR: 0.000996, mAP@0.5: 0.6244
2025-05-21 14:50:59,296 - Epoch 48/100 | Train Loss: 0.2048, LR: 0.000996, mAP@0.5: 0.6461
2025-05-21 14:52:01,734 - Epoch 49/100 | Train Loss: 0.1993, LR: 0.000996, mAP@0.5: 0.6338
2025-05-21 14:53:04,240 - Epoch 50/100 | Train Loss: 0.1979, LR: 0.000996, mAP@0.5: 0.6764
2025-05-21 14:54:06,793 - Epoch 51/100 | Train Loss: 0.2035, LR: 0.000996, mAP@0.5: 0.6059
2025-05-21 14:55:09,252 - Epoch 52/100 | Train Loss: 0.2002, LR: 0.000996, mAP@0.5: 0.6749
2025-05-21 14:56:11,758 - Epoch 53/100 | Train Loss: 0.1976, LR: 0.000996, mAP@0.5: 0.6456
2025-05-21 14:57:14,268 - Epoch 54/100 | Train Loss: 0.1971, LR: 0.000996, mAP@0.5: 0.6538
2025-05-21 14:58:16,837 - Epoch 55/100 | Train Loss: 0.1956, LR: 0.000996, mAP@0.5: 0.6522
2025-05-21 14:59:19,233 - Epoch 56/100 | Train Loss: 0.2023, LR: 0.000996, mAP@0.5: 0.6557
2025-05-21 15:00:21,650 - Epoch 57/100 | Train Loss: 0.1906, LR: 0.000996, mAP@0.5: 0.6663
2025-05-21 15:01:24,108 - Epoch 58/100 | Train Loss: 0.1889, LR: 0.000996, mAP@0.5: 0.6848
2025-05-21 15:02:26,594 - Epoch 59/100 | Train Loss: 0.1872, LR: 0.000996, mAP@0.5: 0.6327
2025-05-21 15:03:29,065 - Epoch 60/100 | Train Loss: 0.1819, LR: 0.000996, mAP@0.5: 0.6507
2025-05-21 15:04:31,504 - Epoch 61/100 | Train Loss: 0.1827, LR: 0.000996, mAP@0.5: 0.6346
2025-05-21 15:05:33,976 - Epoch 62/100 | Train Loss: 0.1858, LR: 0.000996, mAP@0.5: 0.6460
2025-05-21 15:06:36,420 - Epoch 63/100 | Train Loss: 0.1820, LR: 0.000996, mAP@0.5: 0.6667
2025-05-21 15:07:38,800 - Epoch 64/100 | Train Loss: 0.1759, LR: 0.000996, mAP@0.5: 0.6457
2025-05-21 15:08:41,186 - Epoch 65/100 | Train Loss: 0.1755, LR: 0.000996, mAP@0.5: 0.6755
2025-05-21 15:09:43,588 - Epoch 66/100 | Train Loss: 0.1748, LR: 0.000996, mAP@0.5: 0.7091
2025-05-21 15:10:46,172 - Epoch 67/100 | Train Loss: 0.1755, LR: 0.000996, mAP@0.5: 0.6275
2025-05-21 15:11:48,652 - Epoch 68/100 | Train Loss: 0.1752, LR: 0.000996, mAP@0.5: 0.6770
2025-05-21 15:12:51,076 - Epoch 69/100 | Train Loss: 0.1759, LR: 0.000996, mAP@0.5: 0.6667
2025-05-21 15:13:53,468 - Epoch 70/100 | Train Loss: 0.1681, LR: 0.000996, mAP@0.5: 0.6475
2025-05-21 15:14:55,881 - Epoch 71/100 | Train Loss: 0.1682, LR: 0.000996, mAP@0.5: 0.6328
2025-05-21 15:15:58,360 - Epoch 72/100 | Train Loss: 0.1680, LR: 0.000996, mAP@0.5: 0.6761
2025-05-21 15:17:00,774 - Epoch 73/100 | Train Loss: 0.1643, LR: 0.000996, mAP@0.5: 0.6608
2025-05-21 15:18:03,137 - Epoch 74/100 | Train Loss: 0.1731, LR: 0.000996, mAP@0.5: 0.6218
2025-05-21 15:19:05,513 - Epoch 75/100 | Train Loss: 0.1628, LR: 0.000996, mAP@0.5: 0.6681
2025-05-21 15:20:07,822 - Epoch 76/100 | Train Loss: 0.1618, LR: 0.000996, mAP@0.5: 0.6348
2025-05-21 15:20:07,822 - Early stopping at epoch 76
2025-05-21 15:20:07,909 - Model saved at 'models/faster_rcnn_10_byol/faster_rcnn_10_byol_20250521_140221.pth'
2025-05-21 15:20:30,497 - {'map': tensor(0.7230), 'map_50': tensor(0.7230), 'map_75': tensor(-1.), 'map_small': tensor(0.7061), 'map_medium': tensor(0.7388), 'map_large': tensor(-1.), 'mar_1': tensor(0.8540), 'mar_10': tensor(0.9135), 'mar_100': tensor(0.9135), 'mar_small': tensor(0.8990), 'mar_medium': tensor(0.9424), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)}
2025-05-21 15:20:30,502 - Total Duration: 1:18:08.545306
